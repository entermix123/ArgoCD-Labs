Quick Windows Install - ArgoCD

This instruction is for installing cluster modules on Wiondows included in the work of real life CI/CD pipelines
	- Kubernetes Kind Cluster
	- ArgoCD
	- Argo Rollouts
	- Argo Workflows
	- MinIO on the cluster

All prerequisites should be already installed: Docker, Kind, Kubectl, Helm, Nexus, Argo CLI and more from the full instruction - Kubernetes Kind ArgoCD Install Guide for Windows.txt


Cluster
-------

Create cluster 
	terminal --> kind create cluster --config kind-config-nginx.yaml --image kindest/node:v1.34.0

Set roles for worker nodes
	terminal --> kubectl label nodes kind-worker kind-worker2 node-role.kubernetes.io/worker= --overwrite

Rename the local cluster with secret
	terminal --> k apply -f local-secret.yaml


ArgoCD
------

Before installing ArgoCD with nginx ingress controller we need to install nginx deployment
	terminal --> kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.11.0/deploy/static/provider/kind/deploy.yaml

Edit the deployment and add '--enable-ssl-passthrough' flag in specs
	terminal --> k edit deployment ingress-nginx-controller -n ingress-nginx

------------------------------------------------------------
...
    spec:
      containers:
      - args:
        - /nginx-ingress-controller
        - --election-id=ingress-nginx-leader
        - --controller-class=k8s.io/ingress-nginx
        - --ingress-class=nginx
        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
        - --validating-webhook=:8443
        - --validating-webhook-certificate=/usr/local/certificates/cert
        - --validating-webhook-key=/usr/local/certificates/key
        - --watch-ingress-without-class=true
        - --enable-metrics=false
        - --publish-status-address=localhost
        - --enable-ssl-passthrough						# added
...
------------------------------------------------------------
save changes

Install ArgoCD with nginx ingress controller
	terminal --> helm install argocd argo/argo-cd -f values-nginx-simplified.yaml -n argocd --create-namespace

Wait a minute and find initial password for ArgoCD:
	shell terminal --> k -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($_)) }

	# result: password 

Connect to the Node with ArgoCD CLI
	terminal --> argocd login argocd.localhost:32074 --insecure --grpc-web --username admin --password <password>

Wait a minute and access ArgoCD on https://argocd.localhost:32074



Argo Rollouts
-------------

Create argo-rollouts namespace
	terminal --> kubectl create namespace argo-rollouts

Apply argo-rollouts manifest into argo-rollouts namepsace
	terminal --> kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml

Install kargo dashboard
	terminal --> kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/dashboard-install.yaml

Create the service for Argo Rollouts
	terminal --> kubectl apply -f dashboard-ingress.yaml -n argo-rollouts

Open Kargo Dashboard on http://rollouts.localhost:32073/




Argo Workflows
==============

Create installation 'argo' namespace
	terminal --> k create ns argo


HELM:
.....
Deploy Aego Workflows Helm Chart
	terminal --> helm install my-workflow argo/argo-workflows -n argo -f argo-workflows-values.yaml

Create rolebinding for admin role in 'argo' namespace so we can execute actions with Argo Workflows UI
	terminal --> k create rolebinding default-admin --clusterrole=admin --serviceaccount=argo:default -n argo


Manual:
.......
Deploy Argo Workflows manifests
	terminal --> kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/latest/download/install.yaml

Create rolebinding for admin role in 'argo' namespace so we can execute actions with Argo Workflows UI
	terminal --> k create rolebinding default-admin --clusterrole=admin --serviceaccount=argo:default -n argo

Deploy the argo-workflows-ingress.yaml resource
	terminal --> k apply -f argo-workflows-ingress.yaml

Patch the argo workflow server to avoid authentication (NOT FOR PRODUCTION !)
	shell terminal --> kubectl patch deployment argo-server -n argo --type='json' -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/args", "value": ["server", "--auth-mode=server"]}]'

Wait a minute and access our Argo Worflows UI on https://argo-workflows.localhost:32074/



ARGO EVENTS
-----------

WE NEED TO HAVE INSTALLED ARGO WORKFLOWS TO INSTALL ARGO EVENTS - https://argoproj.github.io/argo-events/quick_start/

Official Installation instructions - https://argoproj.github.io/argo-events/installation/

1. Create argo events namespace
	terminal --> kubectl create namespace argo-events


2. Deploy Argo Events SA, ClusterRoles, and Controller for Sensor, EventBus, and EventSource
	terminal --> kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/install.yaml
	terminal -> kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/install-validating-webhook.yaml


3. Deploy the eventbus
	terminal --> kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml


4. Create a service account with RBAC settings to allow the sensor to trigger workflows, and allow workflows to function
	Sensor RBAC - allows sensor to trigger workflows
		terminal --> kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/rbac/sensor-rbac.yaml

	Workflow RBAC - allows workflows to function properly
		terminal --> kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/rbac/workflow-rbac.yaml





CONFIGURE ARGO WORKFLOWS PERMISSIONS IN ARGO-EVENTS NAMESPACE 
=============================================================

We have 4 cases
	- case 1 - if Argo Workflows is installed with HELM and we use default namespace service account
	- case 2 - if Argo Workflows is installed with HELM and we use dedicated namespace service account
	- case 3 - if Argo Workflows is installed manually and we use default namespace service account
	- case 4 - if Argo Workflows is installed manually and we use dedicated namespace service account

There is some differences that matters in audit point of view but all cases work. 


IF ARGO WORKFLOWS IN INSTALLED WITH HELM
----------------------------------------

Scenario 1 - Working with the default user account of the working namespace
----------

Give workflow-controller permissions to act with pods in the working namespace:
	terminal --> kubectl create rolebinding workflow-controller-admin --clusterrole=admin --serviceaccount=argo:my-workflow-argo-workflows-workflow-controller -n argo-events

Give permissions to the working namespace's default service account:
	terminal --> k create rolebinding default-admin --clusterrole=admin --serviceaccount=argo-events:default -n argo-events



Scenario 2 - Create separate service account for the working namespace
----------

Give workflow-controller permissions to act with pods in the working namespace:
	terminal --> kubectl create rolebinding workflow-controller-admin --clusterrole=admin --serviceaccount=argo:my-workflow-argo-workflows-workflow-controller -n argo-events

Create service account in working 'argo-events' namespace
	terminal --> kubectl create serviceaccount argo-workflows -n argo-events

Create rolebinding for the created service account and give it admin rights
	terminal --> kubectl create rolebinding argo-workflows-admin --clusterrole=admin --serviceaccount=argo-events:argo-workflows -n argo-events



IF ARGO WORKFLOWS IN INSTALLED MANUALLY
---------------------------------------

Scenario 1 - Working with the default service account
----------
Give workflow-controller permissions (NOTE: different service account name)
	terminal --> kubectl create rolebinding workflow-controller-admin --clusterrole=admin --serviceaccount=argo:argo -n argo-events

Give permissions to working namespace's default service account
	terminal --> kubectl create rolebinding default-admin --clusterrole=admin --serviceaccount=argo-events:default -n argo-events


Scenario 2 - Create separate service account
----------
Give workflow-controller permissions (NOTE: different service account name)
	terminal --> kubectl create rolebinding workflow-controller-admin --clusterrole=admin --serviceaccount=argo:argo -n argo-events

Create service account
	terminal --> kubectl create serviceaccount argo-workflows -n argo-events

Give it permissions
	terminal --> kubectl create rolebinding argo-workflows-admin --clusterrole=admin --serviceaccount=argo-events:argo-workflows -n argo-events


NOTES:
------
- The key difference between HELM and Manual is the service account name in 'argo' namespace
  * HELM: argo:my-workflow-argo-workflows-workflow-controller
  * Manual: argo:argo
- Using a dedicated service account (Scenarios 2 & 4) is more secure for production
- For development/testing, default service account (Scenarios 1 & 3) is simpler





MinIO
-----

Install MinIO chart
	terminal --> helm install argo-artifacts minio/minio --set resources.requests.memory=512Mi --set replicas=1 --set persistence.enabled=false --set mode=standalone --set rootUser=admin --set rootPassword=password123 --set buckets[0].name=my-bucket --set buckets[0].policy=none --set buckets[0].purge=false -n argo

Apply ingress manifest
	terminal --> k apply -f minio-ingress.yaml -n argo

Create credentials secret in working namespace
	terminal --> k create secret generic my-minio-cred --from-literal=access-key=admin --from-literal=secret-key=password123 -n argo-events

Create the configmap into the working namespace
	terminal --> kubectl apply -f minio-artifact-repo-cm.yaml -n argo-events

Use MinIO
---------

Find Creadentials:

We can print the secret and see the json paths
	terminal --> k get secret argo-artifacts-minio -n argo -o yaml

Decode the username (rootUser) with shell
	terminal --> kubectl get secret argo-artifacts-minio -n argo -o jsonpath='{.data.rootUser}' | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([Convert]::FromBase64String($_.Trim())) }

	# result: admin

Decode the password (rootPassword) with shell
	terminal --> kubectl get secret argo-artifacts-minio -n argo -o jsonpath='{.data.rootPassword}' | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([Convert]::FromBase64String($_.Trim())) }

	# result: password123

Access the MinIO app on http://minio.localhost:32073/login


Configure all nodes to pull images from nexus
---------------------------------------------
Configure nodes to pull images
	terminal --> kubectl apply -f containerd-config-daemonset.yaml

Wait a minute and check connuctivity
	terminal --> kubectl get nodes

Wait a minute and delete the daemonset
	terminal --> kubectl delete daemonset containerd-registry-config -n kube-system



Proceed with the CI/CD pipeline
===============================

Set the default namespace
	terminal --> k config set-context --current --namespace=argo-events

Check the default namespace
	terminal --> kubectl config get-contexts

	# result:
	CURRENT   NAME            CLUSTER         AUTHINFO        NAMESPACE
	          kind-cluster2   kind-cluster2   kind-cluster2
	*         kind-kind       kind-kind       kind-kind       argo-events	# current namespace



GENERATE GITHUB CREDENTIALS
---------------------------

We need to provide GitHub credentials to our workflow to access the application repository and manage it - clone it, make changes to the manifests etc.

Login to GitHub - https://github.com/
Go to https://github.com/settings/tokens
	- Generate New Token (classic)
		- Name: argo-workflows
		- Scope
			- repo - Full control of private repositories 
			- workflow - Update GitHub Action workflows (Optional)
		- Generate Token
	- Copy the value (save it safe temporary)

Create local environment variables with GitHub Username and Token
	terminal --> $GITHUB_USERNAME = "git_username"			# set your username
	terminal --> $GitHubTokenName = "argo-workflows"		# set the token name
	terminal --> $GITHUB_TOKEN = "generated_token"			# set the token

Test the creation of the environment cariables
	terminal --> echo $GITHUB_USERNAME
	terminal --> echo $GitHubTokenName
	terminal --> echo $GITHUB_TOKEN


Create secretfor workflow task in the next step in the same terminal session else the envs will be deleted and the access will be denied.


We will use the environment variables to create secrets objects in our Kubernetes cluster and set them in the workflow.

CREATE SECRETS FOR GITHUB CREDENTAILS IN THE SAME SHELL SESSION
---------------------------------------------------------------

Create secret in our working namespace to use GitHub credentials safetly
	terminal --> kubectl create secret generic github-credentials --from-literal=username=$GITHUB_USERNAME --from-literal=token_name=$GitHubTokenName --from-literal=token=$GITHUB_TOKEN -n argo-events
	
	# result: secret/github-credentials created




14. Install Nexus private image registry
========================================

1. Download and install Java from: https://www.oracle.com/java/technologies/downloads/#jdk25-windows

	Confirm java installation
		terminal --> java -version

2 Download Nexus Repository OSS (Open Source) for Windows - https://www.sonatype.com/products/nexus-community-edition-download

3. Install Nexus
	- unarchive on the PC and navigate to the folder
	- Open shell as administrator and run
		terminal --> .\install-nexus-service.bat

4. Start Nexus service
	terminal --> net start SonatypeNexusRepository

	Check if port 8081 is listening
		terminal --> netstat -ano | findstr :8081

5. Login to Nexus on http://localhost:8081/#login

	Find the initial generated credentials in the installed directory 'sonatype-work\nexus3\admin.password' or with shell
		terminal --> type E:\Installed\nexus-3.88.0-08-win-x86_64\sonatype-work\nexus3\admin.password

	Login to the app and finish the installtion. Relogin.
		Username: admin
		Password: admin123		(default)


Create Nexus repository - example usage
---------------------------------------
- Open Nexus - http://localhost:8081
- Go to Settings/Repositories/Create Repository/docker(hosted)
	- Name: argo-demo
	- Other Connectors
		- HTTP: 8085
	- Docker Registry API Support
		Select Checkbox "Allow clients to use the V1 API to interact with this repository"
	- Create Repository

- Go to Settings/Security/Realms
	- Set Docker Bearer Token Realm to Active
	- Save

 

Configure Docker Desktop to communicate with the created repository
	- Open Docker/Settings/Docker Engine
	- Add
	-------------------------------------------------
	{
	  "insecure-registries": ["localhost:8085"]
	}
	-------------------------------------------------
	- Apply and Restart



Test Docker connection with Nexus by pushing the image created earlier
	Login to Nesus true the configured address
		terminal --> docker login host.docker.internal:8085
		terminal --> admin
		terminal --> nexsus_password

	Retag (rename) and push the image we created earlier to the Nexus repository
		terminal --> docker tag nginx:v1 host.docker.internal:8085/argo-demo/nginx:alpine
		terminal --> docker push host.docker.internal:8085/argo-demo/nginx:alpine

	The image should be visualized in the Nexus repository
		- Go to http://localhost:8081/#browse/browse
		- Then navigate to v2/argo-demo/nginx/tags




Configure Argo Workflows to pull/push images from/to Nexus
----------------------------------------------------------

We need to allow Argo Workflows communication in the Docker Engine Settings to be able to access Nexus platofrm. In this case we are using Docker Desktop and we add the internal Docker host address and the port of the Nexus repository.

Configure Argo Workflows to communicate with Nexus repository
	- Open Docker/Settings/Docker Engine
	- Add
	-------------------------------------------------
	{
	  "insecure-registries": ["localhost:8085", "host.docker.internal:8085"]
	}
	-------------------------------------------------
	- Apply and Restart



Configure Argo Workflows to pull images from Nexus
--------------------------------------------------


Create containerd daemonset configuration

containerd-config-daemonset.yaml
-------------------------------------------------
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: containerd-registry-config
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: containerd-registry-config
  template:
    metadata:
      labels:
        name: containerd-registry-config
    spec:
      hostPID: true
      hostNetwork: true
      initContainers:
      - name: configure-containerd
        image: alpine:latest
        command:
        - sh
        - -c
        - |
          set -e
          
          # Check if configuration already exists
          if grep -q "host.docker.internal:8085" /host/etc/containerd/config.toml 2>/dev/null; then
            echo "Registry configuration already exists, skipping..."
            exit 0
          fi
          
          # Append registry configuration
          cat >> /host/etc/containerd/config.toml << 'EOF'

          [plugins."io.containerd.grpc.v1.cri".registry.mirrors."host.docker.internal:8085"]
            endpoint = ["http://host.docker.internal:8085"]
          [plugins."io.containerd.grpc.v1.cri".registry.configs."host.docker.internal:8085".tls]
            insecure_skip_verify = true
          EOF
          
          echo "Configuration added successfully"
          
          # Find and restart containerd process
          CONTAINERD_PID=$(nsenter -t 1 -m -u -i -n -p pgrep containerd | head -n 1)
          if [ -n "$CONTAINERD_PID" ]; then
            echo "Sending SIGHUP to containerd (PID: $CONTAINERD_PID)"
            nsenter -t 1 -m -u -i -n -p kill -HUP $CONTAINERD_PID
            sleep 2
            echo "Containerd reloaded"
          else
            echo "Warning: Could not find containerd process"
          fi
        securityContext:
          privileged: true
        volumeMounts:
        - name: containerd-config
          mountPath: /host/etc/containerd
      containers:
      - name: pause
        image: registry.k8s.io/pause:3.9
        resources:
          requests:
            cpu: 1m
            memory: 4Mi
      volumes:
      - name: containerd-config
        hostPath:
          path: /etc/containerd
          type: Directory
      tolerations:
      - operator: Exists
-------------------------------------------------

Apply the deamonset
	terminal --> kubectl apply -f containerd-config-daemonset.yaml

	# result: daemonset.apps/containerd-registry-config created

Test nodes communication
	terminal --> k get nodes

Wait 2 minutes and delete the daemonset
	terminal --> kubectl delete -f containerd-config-daemonset.yaml



Give Argo Workflows access to Nexus
-----------------------------------

For this task we need to create Docker secret called 'docker-config-secret' in our Argo Workflows working 'argo-events' namespace. We have to mount our docker credentials to this sescret.

We need to create docker-config.json file and set the Nexus credentials so the workflow can pull and push images.

1. Encode the nexus creadentials with shell
	terminal --> $auth = [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes("admin:admin123"))
$auth
	result: YWRtaW46YWRtaW4xMjM=

2. Create docker-config.json
-----------------------------------------
{
  "auths": {
    "host.docker.internal:8085": {
      "auth": "YWRtaW46YWRtaW4xMjM="
    }
  }
}
-----------------------------------------

From the folder location create Docker secret
	terminal --> kubectl create secret generic docker-config-secret --from-file=config.json=./docker-config.json -n argo-events

	# result: secret/docker-config-secret created





GENERATE GITHUB CREDENTIALS
---------------------------

We need to provide GitHub credentials to our workflow to access the application repository and manage it - clone it, make changes to the manifests etc.

Login to GitHub - https://github.com/
Go to https://github.com/settings/tokens
	- Generate New Token (classic)
		- Name: argo-workflows
		- Scope
			- repo - Full control of private repositories 
			- workflow - Update GitHub Action workflows (Optional)
		- Generate Token
	- Copy the value (save it safe temporary)

Create local environment variables with GitHub Username and Token
	terminal --> $GITHUB_USERNAME = "git_username"			# set your username
	terminal --> $GitHubTokenName = "argo-workflows"		# set the token name
	terminal --> $GITHUB_TOKEN = "generated_token"			# set the token

Test the creation of the environment cariables
	terminal --> echo $GITHUB_USERNAME
	terminal --> echo $GitHubTokenName
	terminal --> echo $GITHUB_TOKEN


Create secretfor workflow task in the next step in the same terminal session else the envs will be deleted and the access will be denied.


We will use the environment variables to create secrets objects in our Kubernetes cluster and set them in the workflow.

CREATE SECRETS FOR GITHUB CREDENTAILS IN THE SAME SHELL SESSION
---------------------------------------------------------------

Create secret in our working namespace to use GitHub credentials safetly
	terminal --> kubectl create secret generic github-credentials --from-literal=username=$GITHUB_USERNAME --from-literal=token_name=$GitHubTokenName --from-literal=token=$GITHUB_TOKEN -n argo-events
	
	# result: secret/github-credentials created





Install local GitLab repository with Docker 
-------------------------------------------

Create volumes on your Windows PC
	terminal --> mkdir D:\Docker\gitlab\config
	terminal --> mkdir D:\Docker\gitlab\logs
	terminal --> mkdir D:\Docker\gitlab\data

Start Docker container with GitLab with exact version (if we use latest we can update the version and lose the configs)
	terminal --> docker run -d --hostname gitlab.local --name gitlab -p 80:80 -p 443:443 -p 22:22 --restart always -v D:\Docker\gitlab\config:/etc/gitlab -v D:\Docker\gitlab\logs:/var/log/gitlab -v D:\Docker\gitlab\data:/var/opt/gitlab gitlab/gitlab-ce:18.8.1-ce.0


Set new password
----------------

Connecto the gitlab container
	terminal --> docker exec -it gitlab bash

Run the GitLab Rails console
		terminal --> gitlab-rails console -e production

Set the new password adn save it
		terminal --> user = User.find_by(username: 'root')
		terminal --> user.password = 'YourStrongPassword123!'
		terminal --> user.password_confirmation = 'YourStrongPassword123!'
		terminal --> user.save!

		# result: => true

Exit the console and container
	terminal --> exit
	terminal --> exit

One line shell command (change the password)
	terminal --> docker exec -it gitlab gitlab-rails runner "user = User.find_by(username: 'root'); user.password = 'YourStrongPassword123!'; user.password_confirmation = 'YourStrongPassword123!'; user.save!"

	
Add host address to Windows host list on Windows
	- Open power Shell as Admin
		terminal --> notepad C:\Windows\System32\drivers\etc\hosts
		- add '127.0.0.1 gitlab.local'
		- save the file and exit

Add host address to Windows host list on Linux
	terminal --> sudo vim /etc/hosts
	- Add '127.0.0.1 gitlab.local'
	- save changes and exit - escape, :wq!, enter



Login to GitLab on http://gitlab.localhost/users/sign_in
	Username: root
	Password: your_password

Create a blank project
	- name: argo-config
	- Project URL: http://gitlab.localhost/root/argo-config
	- Create project

Creaet another project for our app
	- name: my-app
	- Project URL: http://gitlab.localhost/root/my-app
	- Create project



TEST CLUSTER <--> GITLAB CONNECTION
-----------------------------------

Our cluster must be connected with our GitLab server. In this case we are running both via Docker containers

Find our GitLab IP address
	terminal --> docker network inspect bridge | Select-String "Gateway"

	# result: 172.17.0.1

Test connections between cluster and GitLab
	Try to reach Kind cluster from GitLab container
		terminal --> docker exec -it gitlab curl -v http://172.17.0.1:32073
	Try to reach GitLab container from Kind cluster
		terminal --> docker exec -it kind-control-plane curl -v http://172.17.0.1

	# if successfull we will set this IPs for connection between gitlab and kind cluster


GENERATE GITLAB ACCESS TOKEN
----------------------------

Create User Personal Token to connect the 'argo-config' repository to ArgoCD
	- connect to GitLab container
		terminal --> docker exec -it gitlab gitlab-rails console

	- Find the admin user 
		terminal --> user = User.find_by(username: 'root')


	- create personal token
		terminal --> 
token = user.personal_access_tokens.create(
  name: 'gitlab-full-access',
  scopes: ['api', 'read_repository', 'write_repository'],
  expires_at: 1.year.from_now
)
	
	- Display the token - COPYAND SAVE THE TOKEN IMMEDIATELY!
		terminal --> 
puts "=" * 60
puts "TOKEN: #{token.token}"
puts "=" * 60

	- Verify creation
		terminal --> 
if token.persisted?
  puts "✅ Token created successfully!"
  puts "Name: #{token.name}"
  puts "Scopes: #{token.scopes}"
else
  puts "❌ Error: #{token.errors.full_messages}"
end

	- Exit
		terminal --> exit	


Create access token for argo-config project
	- go tp my-app repo/ Settings/Access tokens/Add new token
		- Token name: argo-config-token
		- Expiration date: No Expiration Date
		- Select a role: Maintainer
			- check 'api', 'read_repository' and 'write_repository' option
		- Create project access token

Create access token for my-app project
	- go tp my-app repo/ Settings/Access tokens/Add new token
		- Token name: my-app-token
		- Expiration date: No Expiration Date
		- Select a role: Maintainer
			- check 'api', 'read_repository' and 'write_repository' option
		- Create project access token

We can use different tokens for the different projects (my-app and argo-config) We can use one user access token - not a good practice.

Since the user is the same we use one env var in both secrets.


ALLOW LOCAL HOOKS
-----------------
Go to GitLab/Admin/Settings/Network/Outbound requests/
	- check 'Allow requests to the local network from webhooks and integrations'
	- check 'Allow requests to the local network from system hooks'
	- in the Local IP addresses and domain names ... add
		172.17.0.1
		127.0.0.1
		argo.events
	- Save Changes



CREATE ENV VARIABLES WITH GITLAB CREDENTIALS 
--------------------------------------------
Create local environment variables with GitLab Username and Tokens
	terminal --> $GITLAB_USERNAME = "root"				# set your username
	terminal --> $GITLAB_USER_TOKEN = "generated_user_token"	# set your user token
	terminal --> $GITLAB_CONFIG_TOKEN = "generated_config_token"	# set the config token
	terminal --> $GITLAB_APP_TOKEN = "generated_app_token"		# set the app token

Test the creation of the environment cariables
	terminal --> echo $GITLAB_USERNAME
	terminal --> echo $GITLAB_USER_TOKEN
	terminal --> echo $GITLAB_APP_TOKEN
	terminal --> echo $GITLAB_CONFIG_TOKEN


CREATE SECRETS FOR GITLAB CREDENTAILS
-------------------------------------
Create secret in 'argo-events' namespace to use GitLab credentials for creating the webhook in my-app project
	terminal --> kubectl create secret generic app-repo-credentials --from-literal=username=$GITLAB_USERNAME --from-literal=token=$GITLAB_APP_TOKEN -n argo-events

	# result: secret/app-repo-credentials created

Create secret in 'argo-events' namespace to use GitLab credentials for managing used image in the roolout in argo-config project
	terminal --> kubectl create secret generic config-repo-credentials --from-literal=username=$GITLAB_USERNAME --from-literal=token=$GITLAB_CONFIG_TOKEN -n argo-events

	# result: secret/github-credentials created

We use this secret in event source and in the sersor manifests.



GIVE ARGOCD ACCESS TO GITLAB REPO
---------------------------------

Create secret for GitLab repository access
	terminal --> kubectl create secret generic argocd-gitlab-repo --from-literal=username=root --from-literal=password=$GITLAB_USER_TOKEN --from-literal=url=http://172.17.0.1/root/argo-config.git -n argocd

Label it so ArgoCD recognizes it as a repository credential
	terminal --> kubectl label secret argocd-gitlab-repo argocd.argoproj.io/secret-type=repository -n argocd

Check if the repository is added successfully in ArgoCD UI - https://argocd.localhost:32074/settings/repos



GIVE ARGO WORKFLOWS ACCESS TO NEXUS
-----------------------------------

For this task we need to create Docker secret called 'docker-config-secret' in our Argo Workflows working 'argo-events' namespace. We have to mount our docker credentials to this sescret.

We need to create docker-config.json file and set the Nexus credentials so the workflow can pull and push images.

1. Encode the nexus creadentials with shell
	terminal --> $auth = [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes("admin:admin123"))
$auth
	result: YWRtaW46YWRtaW4xMjM=

2. Create docker-config.json
-----------------------------------------
{
  "auths": {
    "host.docker.internal:8085": {
      "auth": "YWRtaW46YWRtaW4xMjM="
    }
  }
}
-----------------------------------------

From the folder location create Docker secret
	terminal --> kubectl create secret generic docker-config-secret --from-file=config.json=./docker-config.json -n argo-events

	# result: secret/docker-config-secret created




22. INSTALL NGROK
=================
We will expose our PC with public domain with ngrok. Download ngrok - https://dashboard.ngrok.com/get-started

Download ngrok for Windows 64bit and extract it in C:\Users\your_user\ngrok.exe

Set Path to the Environment Variables - open power shell as administrator
	admin terminal --> $oldPath = [Environment]::GetEnvironmentVariable("Path", "User")
	admin terminal --> [Environment]::SetEnvironmentVariable("Path", "$oldPath;C:\Users\your-user", "User")   # change user

Test ngrok installation
	terminal --> ngrok version
	terminal --> Get-Command ngrok

	# result: ngrok version 3.35.0
	# result: Application     ngrok  3.35.0     C:\Users\your-user\ngrok.exe
	

Run the following command to add your authtoken to the default ngrok.yml configuration file.
	terminal --> ngrok config add-authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

We will use this command later to expose our PC with the command
	terminal --> ngrok http 32073					# USE LATER !!!

Copy the address shown in the next section to set it in the Argo event-source.yaml manifest.

To prevent usage of the domain in by external requests we will set additional webhook secret.








Deploy analysis application
---------------------------

1. Build and load analysis appplycation on the cluster
	Navigate to the canary-analysis\analysis-app folder and build the image
		trminal --> docker build -t web-analysis .

	Load the image into the cluster
		terminal --> kind load docker-image web-analysis --name kind


2. Create canary-analysis namespace
	terminal --> k create ns canary-analysis

	# result: namespace/canary-analysis created


3. Deply the analysis CRD in the 'canary-analysis' namespace
	terminal --> k apply -f canary-analysis.yaml

	# result: clusteranalysistemplate.argoproj.io/success-rate created

4. Apply the analysis deployment
	terminal --> k apply -f web-analysis-deployment.yaml -n canary-analysis

	# result:
	deployment.apps/web-analysis created
	service/web-analysis created

5. Check if the serice is running
	terminal --> kubectl get pods -n canary-analysis -l app=web-analysis

	# result:
	NAME                            READY   STATUS    RESTARTS   AGE
	web-analysis-5f9bc64f67-2tgn6   1/1     Running   0          6m29s


















